# Battle of the LLMs - Summarizer Showdown ü§ñ vs ü§ñ

A modern React application for comparing text summaries generated by different language models, allowing users to evaluate and compare performance between open-source models (via Hugging Face) and proprietary APIs (OpenAI, Anthropic).



## üìã Overview

This application allows users to:
- Input text for summarization
- Select models from both open-source and proprietary options
- Generate and compare summaries side-by-side
- Rate summaries based on clarity, accuracy, and conciseness
- View analytics on model performance

## ‚ú® Features

- **Diverse Model Selection**: Choose from popular open-source models (BART, Pegasus, T5, Mixtral) and proprietary APIs (GPT-3.5-Turbo, GPT-4o, Claude 3)
- **Efficient Text Processing**: Handle large documents with optimized processing
- **Real-time Summarization**: Generate summaries with parallel API calls
- **Interactive Comparison**: Side-by-side evaluation with intuitive rating system
- **Comprehensive Analytics**: Visualize performance metrics with detailed statistical breakdowns

## üõ†Ô∏è Tech Stack

- **Frontend**: 
  - React 19 with Hooks
  - Bootstrap 5 for responsive UI
  - Chart.js for data visualization
- **API Integration**: 
  - Hugging Face Inference API
  - OpenAI API
  - Axios for HTTP requests
- **Testing**: Jest and React Testing Library

## üöÄ Getting Started

### Prerequisites

- Node.js ‚â• 18.x
- npm ‚â• 9.x or yarn ‚â• 1.22.x
- API keys:
  - Hugging Face ([huggingface.co/settings/tokens](https://huggingface.co/settings/tokens))
  - OpenAI ([platform.openai.com/api-keys](https://platform.openai.com/api-keys))

### Installation

1. Clone the repository
   ```bash
   git clone https://github.com/yourusername/battle-of-the-llms.git
   cd battle-of-the-llms
   ```

2. Install dependencies
   ```bash
   npm install
   # or
   yarn install
   ```

3. Create `.env.local` file for API keys
   ```
   REACT_APP_HUGGINGFACE_API_KEY=your_huggingface_key
   REACT_APP_OPENAI_API_KEY=your_openai_key
   ```

4. Start the development server
   ```bash
   npm start
   # or
   yarn start
   ```

5. Open [http://localhost:3000](http://localhost:3000) to view the app

## üìä Evaluation System

The application uses a comprehensive evaluation framework with three key metrics:

| Metric | Description | Icon |
|--------|-------------|------|
| **Clarity** | Evaluates how clear and understandable the summary is | üîç |
| **Accuracy** | Measures how well the summary preserves the original content's meaning | üéØ |
| **Conciseness** | Assesses how efficiently the summary conveys information | ‚úÇÔ∏è |

Users can also indicate their overall preference between the two summaries, which feeds into the analytics dashboard.

## üì± Application Structure

The application is organized into three main tabs:

1. **Input & Models**
   - Text input area
   - Model selection for both open-source and proprietary options
   - API key configuration

2. **Summary Comparison**
   - Side-by-side display of generated summaries
   - Rating controls for each metric
   - Preference selection

3. **Analytics Dashboard**
   - Performance visualization across metrics
   - Model preference statistics
   - Historical comparison data

## üíª Development

```bash
# Run tests
npm test

# Build for production
npm run build

# Eject from create-react-app
npm run eject
```

## üîç Key Components

- **TextInput**: Handles user text input with character count and validation
- **ModelSelection**: Provides model selection and API configuration
- **SummaryComparison**: Displays generated summaries with evaluation controls
- **AnalyticsDashboard**: Visualizes performance metrics and statistics

